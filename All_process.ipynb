{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 视频转换图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally save 1909 pics\n"
     ]
    }
   ],
   "source": [
    "VIDEO_PATH = 'D:/0LT/chitanda/vedio/05.mkv' # 视频地址\n",
    "EXTRACT_FOLDER = 'D:/0LT/chitanda/vedio_pic/' # 存放帧图片的位置\n",
    "EXTRACT_FREQUENCY = 100 # 帧提取频率\n",
    "\n",
    "def extract_frames(video_path, dst_folder, index):\n",
    "    # 主操作\n",
    "    import cv2\n",
    "    video = cv2.VideoCapture()\n",
    "    if not video.open(video_path):\n",
    "        print(\"can not open the video\")\n",
    "        exit(1)\n",
    "    count = 1\n",
    "    while True:\n",
    "        _, frame = video.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        if count % EXTRACT_FREQUENCY == 0:\n",
    "            save_path = \"{}/{:>04d}.jpg\".format(dst_folder, index)\n",
    "            cv2.imwrite(save_path, frame)\n",
    "            index += 1\n",
    "        count += 1\n",
    "    video.release()\n",
    "    # 打印出所提取帧的总数\n",
    "    print(\"Totally save {:d} pics\".format(index-1))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    extract_frames(VIDEO_PATH, EXTRACT_FOLDER, 1497)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 手动将不需要的图片删除，修改整理好后的图片名称（有序排列）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename()不能修改为已经有的名字，会报错\n",
    "当文件夹内有新旧（打过标签和未打标签）图片时，排序并非看起来的数字排序，所以可能未达标签的顺序可能比较靠前，使得重新命名的时候会命名为\n",
    "已经存在的名字，从而报错。\n",
    "所以最好将打过标签的图片存放在别的文件夹内，等这边的修改完再考进来（此时修改要记住命名的起点不是1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 42 to rename & converted 858 jpgs\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "      \n",
    "class BatchRename():  \n",
    "        #批量重命名文件夹中的图片文件 \n",
    "        def __init__(self):  \n",
    "            self.path = 'D:/0LT/chitanda/VOC2007/JPEGImages/'  #图片文件夹路径\n",
    "      \n",
    "        def rename(self):  \n",
    "            filelist = os.listdir(self.path)  \n",
    "            total_num = len(filelist)  \n",
    "            i = 816  #从1开始排序\n",
    "            for item in filelist:  \n",
    "                if item.endswith('.jpg'):  \n",
    "                    n = 3 - len(str(i))  \n",
    "                    src = os.path.join(os.path.abspath(self.path), item)  \n",
    "                    dst = \"{}{:03d}.jpg\".format(self.path, i) \n",
    "                    try:  \n",
    "                        os.rename(src, dst)  \n",
    "                        i = i + 1 \n",
    "                    except:  \n",
    "                        print(src,dst)\n",
    "                        break  \n",
    "            print('total %d to rename & converted %d jpgs' % (total_num, i))  \n",
    "      \n",
    "if __name__ == '__main__':  \n",
    "        demo = BatchRename()  \n",
    "        demo.rename()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. labelimg给图片打上标签 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size 685\n",
      "train size 548\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "xmlfilepath = r'D:/0LT/chitanda/VOC2007/Annotations/'\n",
    "saveBasePath = r'D:/0LT/chitanda/VOC2007/ImageSets/'\n",
    "\n",
    "trainval_percent = 0.8\n",
    "train_percent = 0.8\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num * trainval_percent)\n",
    "tr = int(tv * train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    "\n",
    "print(\"train and val size\", tv)\n",
    "print(\"train size\", tr)\n",
    "ftrainval = open(os.path.join(saveBasePath, 'Main/trainval.txt'), 'w')\n",
    "ftest = open(os.path.join(saveBasePath, 'Main/test.txt'), 'w')\n",
    "ftrain = open(os.path.join(saveBasePath, 'Main/train.txt'), 'w')\n",
    "fval = open(os.path.join(saveBasePath, 'Main/val.txt'), 'w')\n",
    "\n",
    "for i in list:\n",
    "    name = total_xml[i][:-3] + '\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    "\n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 将图像数据修改tf格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 按照自己的数据集类型修改文件：SSD-Tensorflow/datasets/pascalvoc_common.py，示例如下： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'Chitanda': (1, 'People'),\n",
    "    'Oreki': (2, 'People'),\n",
    "    'Fukube': (3, 'People'),\n",
    "    'Ibara': (4, 'People'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 新建tfrecords_文件，保存tf格式的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 在pycharm里面运行tf_convert_data.py，输入如下参数.第一行和第三行不用更改，二四两行要改成绝对地址。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--dataset_name=pascalvoc\n",
    "--dataset_dir=D:/0LT/chitanda/VOC2007/\n",
    "--output_name=voc_2007_train\n",
    "--output_dir=D:/0LT/chitanda/VOC2007/tfrecords_/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.训练模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 统计数据集的一些信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chitanda 499 499\n",
      "Oreki 558 558\n",
      "Fukube 289 289\n",
      "Ibara 228 228\n",
      "total 857 1574\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class1 = 'Chitanda'\n",
    "class2 = 'Oreki'\n",
    "class3 = 'Fukube'\n",
    "class4 = 'Ibara'\n",
    "annotation_folder = 'D:/0LT/chitanda/VOC2007/Annotations/'  # 改为自己标签文件夹的路径\n",
    "list = os.listdir(annotation_folder)\n",
    "def file_name(file_dir):\n",
    "    L = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.xml':\n",
    "                L.append(os.path.join(root, file))\n",
    "    return L\n",
    "total_number1 = 0\n",
    "total_number2 = 0\n",
    "total_number3 = 0\n",
    "total_number4 = 0\n",
    "total = 0\n",
    "total_pic = 0\n",
    "pic_num1 = 0\n",
    "pic_num2 = 0\n",
    "pic_num3 = 0\n",
    "pic_num4 = 0\n",
    "flag1 = 0\n",
    "flag2 = 0\n",
    "flag3 = 0\n",
    "flag4 = 0\n",
    "xml_dirs = file_name(annotation_folder)\n",
    "\n",
    "for i in range(0, len(xml_dirs)):\n",
    "    #print(xml_dirs[i])\n",
    "    annotation_file = open(xml_dirs[i]).read()\n",
    "    root = ET.fromstring(annotation_file)\n",
    "    total_pic = total_pic + 1\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        if label == class1:\n",
    "            total_number1 = total_number1 + 1\n",
    "            flag1 = 1\n",
    "            total = total + 1\n",
    "        # print(\"bounding box number:\", total_number1)\n",
    "        if label == class2:\n",
    "            total_number2 = total_number2 + 1\n",
    "            flag2 = 1\n",
    "            total = total + 1\n",
    "        if label == class3:\n",
    "            total_number3 = total_number3 + 1\n",
    "            flag3 = 1\n",
    "            total = total + 1\n",
    "        if label == class4:\n",
    "            total_number4 = total_number4 + 1\n",
    "            flag4 = 1\n",
    "            total = total + 1\n",
    "    if flag1 == 1:\n",
    "        pic_num1 = pic_num1 + 1\n",
    "        # print(\"pic number:\", pic_num1)\n",
    "        flag1 = 0\n",
    "    if flag2 == 1:\n",
    "        pic_num2 = pic_num2 + 1\n",
    "        flag2 = 0\n",
    "    if flag3 == 1:\n",
    "        pic_num3 = pic_num3 + 1\n",
    "        flag3 = 0\n",
    "    if flag4 == 1:\n",
    "        pic_num4 = pic_num4 + 1\n",
    "        flag4 = 0\n",
    "print(class1, pic_num1, total_number1)\n",
    "print(class2, pic_num2, total_number2)\n",
    "print(class3, pic_num3, total_number3)\n",
    "print(class4, pic_num4, total_number4)\n",
    "print(\"total\", total_pic, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 按照上面的结果修改pascalvoc_2007.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_STATISTICS = {\n",
    "    'none': (0, 0),\n",
    "    'Chitanda': (289, 289),\n",
    "    'Oreki': (335, 335),\n",
    "    'Fukube': (191, 191),\n",
    "    'Ibara': (105, 105),\n",
    "    'total': (460, 920),\n",
    "}\n",
    "TEST_STATISTICS = {\n",
    "    'none': (0, 0),\n",
    "    'Chitanda': (1, 1),\n",
    "    'Oreki': (1, 1),\n",
    "    'Fukube': (1, 1),\n",
    "    'Ibara': (1, 1),\n",
    "    'total': (4, 4),\n",
    "}\n",
    "SPLITS_TO_SIZES = {\n",
    "    'train': 294,\n",
    "    'test': 92,\n",
    "}\n",
    "SPLITS_TO_STATISTICS = {\n",
    "    'train': TRAIN_STATISTICS,\n",
    "    'test': TEST_STATISTICS,\n",
    "}\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 修改ssd_vgg_300.py     96，97行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " num_classes=5,         #根据自己的数据修改为类别+1 \n",
    " no_annotation_label=5, #根据自己的数据修改为类别+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 修改eval_ssd_network.py    66行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.app.flags.DEFINE_integer('num_classes', 5, 'Number of classes to use in the dataset.')   #类别+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 修改 train_ssd_network.py     35，142，50-74，158，162 行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同上，在pycharm里面运行，train_ssd_network.py 输入如下参数，修改地址即可，其它酌情修改。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1从零开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--train_dir=D:/0LT/SSD_test/checkpoints/\n",
    "--dataset_dir=D:/0LT/chitanda/VOC2007/tfrecords_/\n",
    "--dataset_name=pascalvoc_2007\n",
    "--dataset_split_name=train\n",
    "--model_name=ssd_300_vgg\n",
    "--save_summaries_secs=600\n",
    "--save_interval_secs=600\n",
    "--optimizer=adam\n",
    "--learning_rate=0.001\n",
    "--learning_rate_decay_factor=0.94\n",
    "--batch_size=4\n",
    "--gpu_memory_fraction=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#备注 batch_size不要过大，之前为32，会报错GPU内存不够，现改为8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2加载现有模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--train_dir=D:/0LT/SSD_test/checkpoints/           \n",
    "--dataset_dir=D:/0LT/chitanda/VOC2007/tfrecords_/      \n",
    "--dataset_name=pascalvoc_2007        \n",
    "--dataset_split_name=train   \n",
    "--model_name=ssd_300_vgg              \n",
    "--checkpoint_path=D:/0LT/SSD_test/checkpoints/vgg_16.ckpt\n",
    "--checkpoint_model_scope=vgg_16 \n",
    "--checkpoint_exclude_scopes=ssd_300_vgg/conv6,ssd_300_vgg/conv7,ssd_300_vgg/block8,ssd_300_vgg/block9,ssd_300_vgg/block10,ssd_300_vgg/block11,ssd_300_vgg/block4_box,ssd_300_vgg/block7_box,ssd_300_vgg/block8_box,ssd_300_vgg/block9_box,ssd_300_vgg/block10_box,ssd_300_vgg/block11_box  \n",
    "--trainable_scopes=ssd_300_vgg/conv6,ssd_300_vgg/conv7,ssd_300_vgg/block8,ssd_300_vgg/block9,ssd_300_vgg/block10,ssd_300_vgg/block11,ssd_300_vgg/block4_box,ssd_300_vgg/block7_box,ssd_300_vgg/block8_box,ssd_300_vgg/block9_box,ssd_300_vgg/block10_box,ssd_300_vgg/block11_box  \n",
    "--save_summaries_secs=600 \n",
    "--save_interval_secs=600  \n",
    "--weight_decay=0.0005  \n",
    "--optimizer=adam        \n",
    "--learning_rate=0.0001\n",
    "--learning_rate_decay_factor=0.94\n",
    "--batch_size=4                   \n",
    "--gpu_memory_fraction=0.9    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
